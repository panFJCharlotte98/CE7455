{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture</th>\n",
       "      <th>rouge1_fmeasure</th>\n",
       "      <th>rouge1_precision</th>\n",
       "      <th>rouge1_recall</th>\n",
       "      <th>rouge2_fmeasure</th>\n",
       "      <th>rouge2_precision</th>\n",
       "      <th>rouge2_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRU Encoder + GRU Decoder</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM Encoder + LSTM Decoder</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bi-LSTM Encoder + GRU Decoder</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU Encoder+ Attention + GRU Decoder</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformer Encoder + GRU Decoder</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Architecture  rouge1_fmeasure  rouge1_precision  \\\n",
       "0             GRU Encoder + GRU Decoder            0.657             0.622   \n",
       "1           LSTM Encoder + LSTM Decoder            0.638             0.601   \n",
       "2         bi-LSTM Encoder + GRU Decoder            0.658             0.623   \n",
       "3  GRU Encoder+ Attention + GRU Decoder            0.632             0.597   \n",
       "4     Transformer Encoder + GRU Decoder            0.626             0.595   \n",
       "\n",
       "   rouge1_recall  rouge2_fmeasure  rouge2_precision  rouge2_recall  \n",
       "0          0.707            0.477             0.443          0.526  \n",
       "1          0.688            0.458             0.425          0.506  \n",
       "2          0.708            0.475             0.441          0.525  \n",
       "3          0.683            0.443             0.411          0.491  \n",
       "4          0.672            0.437             0.408          0.482  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Assignment2_results.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import math\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 15\n",
    "\n",
    "# #----------------Helper Funcs----------------#\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "# #---------------- Prepare Datasets and Vocabulary ----------------#\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def filterPair(p):\n",
    "    eng_prefixes = (\n",
    "        \"i am\", \"i m\",\n",
    "        \"he is\", \"he s\",\n",
    "        \"she is\", \"she s\",\n",
    "        \"you are\", \"you re\",\n",
    "        \"we are\", \"we re\",\n",
    "        \"they are\", \"they re\"\n",
    "    )\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "# #-----------------------------Prepare Tensors-------------------------#\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1) # [seq_len, 1]\n",
    "\n",
    "def tensorsFromPair(pair, input_lang, output_lang):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "# \n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH, use_attention=False, use_transformer=False):\n",
    "    teacher_forcing_ratio = 0.5\n",
    "    input_length = input_tensor.size(0) # input_tensor = [seq_len, batch_size=1]\n",
    "    target_length = target_tensor.size(0)\n",
    "    # encoder_hidden = [n_layer * n_direction=1, batch_size, hidden_size]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # encoder_outputs = [seq_len, n_direction * hidden_size]\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size * encoder.n_direction, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    if use_transformer:\n",
    "        # ------------------- Follow Task Instruction -------------------#\n",
    "        # Note: You should take the mean of all hidden representation output from the transformer encoder of each token to be a sentence representation of the encoder.\n",
    "        # Also, for the transformer encoder, you must input the whole sentence instead of feeding word by word to get the next token representation.\n",
    "        encoder_outputs = encoder(input_tensor) # encoder_ouputs = [seq_len, batch_size, hidden_size]\n",
    "        #print(encoder_outputs.size())\n",
    "        \n",
    "        # encoder_hidden : sentence representation\n",
    "        encoder_hidden = torch.mean(encoder_outputs, dim=0, keepdim=True) # [1, batch_size, hidden_size]\n",
    "        #encoder_hidden = torch.max(encoder_outputs, dim=0, keepdim=True).values\n",
    "        # print(encoder_hidden.size())\n",
    "        # exit()\n",
    "        encoder_outputs = encoder_outputs.squeeze(1)\n",
    "    else:\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden) # encoder_output = [seq_len, batch_size, hidden_size]\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    \n",
    "    if (\"LSTM\" in encoder.rnn_type) and ('LSTM' not in decoder.rnn_type):\n",
    "        decoder_hidden = encoder_hidden[0].view(1, 1, -1)\n",
    "    else:\n",
    "        decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            if use_attention:\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            if use_attention:\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "def trainIters(encoder, decoder, input_lang, output_lang, train_pairs, epochs, print_every=1000, plot_every=100, learning_rate=0.01, use_attention=False, use_transformer=False):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    iter = 1\n",
    "    n_iters = len(train_pairs) * epochs\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(\"Epoch: %d/%d\" % (epoch, epochs))\n",
    "        for training_pair in tqdm(train_pairs):\n",
    "            training_pair = tensorsFromPair(training_pair, input_lang, output_lang)\n",
    "\n",
    "            input_tensor = training_pair[0]\n",
    "            target_tensor = training_pair[1]\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                        decoder, encoder_optimizer, decoder_optimizer, criterion, use_attention=use_attention, use_transformer=use_transformer)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                            iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            iter +=1\n",
    "\n",
    "# # -----------------------------Predict Step-----------------------------------#\n",
    "def prediction_step(encoder, decoder, input_lang, output_lang, sentence, max_length=MAX_LENGTH, use_attention=False, use_transformer=False):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size * encoder.n_direction, device=device)\n",
    "        if use_transformer:\n",
    "            # ------------------- Follow Task Instruction -------------------#\n",
    "            # Note: You should take the mean of all hidden representation output from the transformer encoder of each token to be a sentence representation of the encoder.\n",
    "            # Also, for the transformer encoder, you must input the whole sentence instead of feeding word by word to get the next token representation.\n",
    "            encoder_outputs = encoder(input_tensor) # encoder_ouputs = [seq_len, batch_size, hidden_size]\n",
    "            # encoder_hidden : sentence representation\n",
    "            encoder_hidden = torch.mean(encoder_outputs, dim=0, keepdim=True) # [1, batch_size, hidden_size]\n",
    "            #encoder_hidden = torch.max(encoder_outputs, dim=0, keepdim=True).values\n",
    "            encoder_outputs = encoder_outputs.squeeze(1)\n",
    "        else:\n",
    "            for ei in range(input_length):\n",
    "                encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "                encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        \n",
    "        if (\"LSTM\" in encoder.rnn_type) and ('LSTM' not in decoder.rnn_type):\n",
    "            decoder_hidden = encoder_hidden[0].view(1, 1, -1)\n",
    "        else:\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        if use_attention:\n",
    "            decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            if use_attention:\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                decoder_attentions[di] = decoder_attention.data\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "            # values, indices, most likely word\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        \n",
    "        if use_attention:\n",
    "            return decoded_words, decoder_attentions[:di + 1]\n",
    "        else:\n",
    "            return decoded_words\n",
    "\n",
    "def test(encoder, decoder, input_lang, output_lang, testing_pairs, use_attention=False, use_transformer=False):\n",
    "    rouge = ROUGEScore()\n",
    "    input = []\n",
    "    gt = []\n",
    "    predict = []\n",
    "    metric_score = {\n",
    "        \"rouge1_fmeasure\":[],\n",
    "        \"rouge1_precision\":[],\n",
    "        \"rouge1_recall\":[],\n",
    "        \"rouge2_fmeasure\":[],\n",
    "        \"rouge2_precision\":[],\n",
    "        \"rouge2_recall\":[]\n",
    "    }\n",
    "    \n",
    "    for i in tqdm(range(len(testing_pairs))):\n",
    "        pair = testing_pairs[i]\n",
    "        if use_attention:\n",
    "            output_words, _ = prediction_step(encoder, decoder, input_lang, output_lang, pair[0], use_attention=use_attention, use_transformer=use_transformer)\n",
    "        else:\n",
    "            output_words = prediction_step(encoder, decoder, input_lang, output_lang, pair[0], use_transformer=use_transformer)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "\n",
    "        input.append(pair[0])\n",
    "        gt.append(pair[1])\n",
    "        predict.append(output_sentence)\n",
    "\n",
    "        try:\n",
    "            rs = rouge(output_sentence, pair[1])\n",
    "        except:\n",
    "            continue\n",
    "        for s_name in list(metric_score.keys()):\n",
    "            metric_score[s_name].append(rs[s_name])\n",
    "        # metric_score[\"rouge1_fmeasure\"].append(rs['rouge1_fmeasure'])\n",
    "        # metric_score[\"rouge1_precision\"].append(rs['rouge1_precision'])\n",
    "        # metric_score[\"rouge1_recall\"].append(rs['rouge1_recall'])\n",
    "        # metric_score[\"rouge2_fmeasure\"].append(rs['rouge2_fmeasure'])\n",
    "        # metric_score[\"rouge2_precision\"].append(rs['rouge2_precision'])\n",
    "        # metric_score[\"rouge2_recall\"].append(rs['rouge2_recall'])\n",
    "    \n",
    "    for s_name in list(metric_score.keys()):\n",
    "        metric_score[s_name] = np.array(metric_score[s_name]).mean()\n",
    "\n",
    "    # metric_score[\"rouge1_fmeasure\"] = np.array(metric_score[\"rouge1_fmeasure\"]).mean()\n",
    "    # metric_score[\"rouge1_precision\"] = np.array(metric_score[\"rouge1_precision\"]).mean()\n",
    "    # metric_score[\"rouge1_recall\"] = np.array(metric_score[\"rouge1_recall\"]).mean()\n",
    "    # metric_score[\"rouge2_fmeasure\"] = np.array(metric_score[\"rouge2_fmeasure\"]).mean()\n",
    "    # metric_score[\"rouge2_precision\"] = np.array(metric_score[\"rouge2_precision\"]).mean()\n",
    "    # metric_score[\"rouge2_recall\"] = np.array(metric_score[\"rouge2_recall\"]).mean()\n",
    "\n",
    "    print(\"=== Evaluation score - Rouge score ===\")\n",
    "    for s_name, s_value in metric_score.items():\n",
    "        print(f\"{s_name}:\\t{s_value}\")\n",
    "    # print(\"Rouge1 fmeasure:\\t\",metric_score[\"rouge1_fmeasure\"])\n",
    "    # print(\"Rouge1 precision:\\t\",metric_score[\"rouge1_precision\"])\n",
    "    # print(\"Rouge1 recall:  \\t\",metric_score[\"rouge1_recall\"])\n",
    "    # print(\"Rouge2 fmeasure:\\t\",metric_score[\"rouge2_fmeasure\"])\n",
    "    # print(\"Rouge2 precision:\\t\",metric_score[\"rouge2_precision\"])\n",
    "    # print(\"Rouge2 recall:  \\t\",metric_score[\"rouge2_recall\"])\n",
    "    print(\"=====================================\")\n",
    "    return input,gt,predict,metric_score\n",
    "\n",
    "# # ----------------------------Model ----------------------------------#\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_vocab_size, hidden_size, rnn=\"GRU\", use_transformer=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_direction = 1\n",
    "\n",
    "        self.embedding = nn.Embedding(input_vocab_size, hidden_size)\n",
    "        \n",
    "        self.use_transformer = use_transformer\n",
    "        if use_transformer:\n",
    "            self.rnn_type = \"\"\n",
    "            self.encoder_layer = nn.TransformerEncoderLayer(d_model=self.hidden_size, nhead=64)#8\n",
    "            self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)#6\n",
    "        else:\n",
    "            self.rnn_type = rnn\n",
    "            if rnn == \"GRU\":\n",
    "                self.rnn = nn.GRU(hidden_size, hidden_size)\n",
    "            elif rnn == \"LSTM\":\n",
    "                self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
    "            elif rnn == \"bi-LSTM\":\n",
    "                self.n_direction = 2\n",
    "                self.rnn = nn.LSTM(hidden_size, hidden_size, bidirectional=True)\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        \n",
    "        if self.use_transformer:\n",
    "            # embedded = [seq_len, batch_size, hidden_size]\n",
    "            embedded = self.embedding(input)\n",
    "            output = self.transformer_encoder(embedded)\n",
    "            return output\n",
    "        else:\n",
    "            embedded = self.embedding(input).view(1, 1, -1)\n",
    "            output = embedded\n",
    "            # output = [seq_len, batch_size, n_direction * hidden_size]\n",
    "            #       containing the output features (h_t) from the last layer of the LSTM, for each time step t\n",
    "            # hidden = [n_layer * n_direction, batch_size, hidden_size]\n",
    "            #       containing the final hidden state\n",
    "            output, hidden = self.rnn(output, hidden) # hidden is a tuple of (hidden, cell)\n",
    "            return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        if self.use_transformer:\n",
    "            return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        else:\n",
    "            if self.rnn_type == \"GRU\":\n",
    "                return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "            elif self.rnn_type == \"LSTM\":\n",
    "                return (torch.zeros(1, 1, self.hidden_size, device=device), torch.zeros(1, 1, self.hidden_size, device=device))\n",
    "            elif self.rnn_type == \"bi-LSTM\":\n",
    "                return (torch.zeros(1 * 2, 1, self.hidden_size, device=device), torch.zeros(1 * 2, 1, self.hidden_size, device=device))\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "              \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_vocab_size, rnn):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_vocab_size, hidden_size)        \n",
    "        self.rnn_type = rnn\n",
    "        if rnn == \"GRU\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size)\n",
    "        elif rnn == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, output_vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Your code here #\n",
    "        # input = [seq_len=1, batch_size=1] e.g.,[[token_id]]\n",
    "        # hidden = [n_layer * n_direction, batch_size, hidden_size]\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        if \"LSTM\" in self.rnn_type:\n",
    "            # output = [seq_len, batch_size, n_direction * hidden_size]\n",
    "            # hidden = [n_layer * n_direction, batch_size, hidden_size]\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "        else:\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def run(\n",
    "    task_name,\n",
    "    input_lang, \n",
    "    output_lang,\n",
    "    train_pairs,\n",
    "    test_pairs,\n",
    "    encoder_rnn=\"GRU\", \n",
    "    decoder_rnn=\"GRU\", \n",
    "    decoder_hidden_size=None,\n",
    "    use_attention=False, \n",
    "    use_transformer=False,\n",
    "):\n",
    "    # Default setting\n",
    "    epochs = 5\n",
    "    hidden_size = 512\n",
    "    encoder1 = Encoder(input_lang.n_words, hidden_size, rnn=encoder_rnn, use_transformer=use_transformer).to(device)\n",
    "    if use_attention:\n",
    "        decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "    else:\n",
    "        d_hidden_size = hidden_size if decoder_hidden_size is None else decoder_hidden_size\n",
    "        decoder1 = Decoder(d_hidden_size, output_lang.n_words, rnn=decoder_rnn).to(device)\n",
    "\n",
    "    trainIters(encoder1, decoder1, input_lang, output_lang, train_pairs, epochs=epochs, print_every=5000, use_attention=use_attention, use_transformer=use_transformer)\n",
    "    #input,gt,predict,score = test(encoder1, decoder1, train_pairs)\n",
    "    input,gt,predict,score = test(encoder1, decoder1, input_lang, output_lang, test_pairs, use_attention=use_attention, use_transformer=use_transformer)\n",
    "    del encoder1\n",
    "    del decoder1\n",
    "    return {task_name: [round(v,3) for k, v in score.items()]}, [k for k, _ in score.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "    X = [i[0] for i in pairs]\n",
    "    y = [i[1] for i in pairs]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    train_pairs = list(zip(X_train,y_train))\n",
    "    test_pairs = list(zip(X_test,y_test))\n",
    "    \n",
    "    all_res_dict = {}\n",
    "    # Task 1\n",
    "    score_vals, score_names = run(\"GRU Encoder + GRU Decoder\", input_lang, output_lang, train_pairs, test_pairs, \\\n",
    "                            encoder_rnn=\"GRU\", decoder_rnn=\"GRU\")\n",
    "    all_res_dict.update(score_vals)\n",
    "\n",
    "    # Task 2\n",
    "    all_res_dict.update(run(\"LSTM Encoder + LSTM Decoder\", input_lang, output_lang, train_pairs, test_pairs, \\\n",
    "                            encoder_rnn=\"LSTM\", decoder_rnn=\"LSTM\")[0])\n",
    "\n",
    "    # Task 3\n",
    "    all_res_dict.update(run(\"bi-LSTM Encoder + GRU Decoder\", input_lang, output_lang, train_pairs, test_pairs, \\\n",
    "                            encoder_rnn=\"bi-LSTM\", decoder_hidden_size=1024, decoder_rnn=\"GRU\")[0])\n",
    "    \n",
    "    # Task 4\n",
    "    all_res_dict.update(run(\"GRU Encoder+ Attention + GRU Decoder\", input_lang, output_lang, train_pairs, test_pairs, \\\n",
    "                            use_attention=True)[0])\n",
    "    \n",
    "    # Task 5\n",
    "    score_vals, score_names = run(\"Transformer Encoder + GRU Decoder\", input_lang, output_lang, train_pairs, test_pairs, \\\n",
    "                            use_transformer=True)\n",
    "    all_res_dict.update(score_vals)\n",
    "    \n",
    "    res_df = pd.DataFrame.from_dict(all_res_dict, orient='index', columns = score_names)\n",
    "    res_df = res_df.reset_index()\n",
    "    res_df.to_csv(\"Assignment2_results.csv\", index=False)\n",
    " \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
